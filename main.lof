\babel@toc {spanish}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Comparación de irradiancia solar diaria entre datos de satélite sin adaptar, datos de satélite adaptados y mediciones locales en el sitio de referencia. Se observa cómo la adaptación al sitio corrige el sesgo sistemático y mejora la representatividad de los datos satelitales.}}{14}{figure.2.1}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Adaptación al Sitio sobre una serie genérica}}{15}{figure.2.2}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Diagrama de dispersión entre mediciones en sitio y estimaciones satelitales. Antes de la adaptación (puntos rojos), los datos muestran un sesgo claro al situarse por debajo de la línea 1:1. Después de la adaptación (puntos verdes), las estimaciones se alinean mucho mejor con la referencia, reduciendo el error sistemático.}}{16}{figure.2.3}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Comparación entre el comando de entrada y los datos de entrada}}{21}{figure.2.4}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Esquema de una neurona artificial}}{22}{figure.2.5}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Esquema de una red neuronal multicapa (MLP).}}{24}{figure.2.6}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Analogía del MLP como un conjunto de expertos neuronales que refinan la predicción de la GHI.}}{25}{figure.2.7}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Ejemplo de un MLP con dos entradas, dos neuronas ocultas y una salida.}}{25}{figure.2.8}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Ejemplo Árbol de Regresión. Para los datos de Hitters, se construye un árbol de regresión para predecir el logaritmo del salario de un jugador de béisbol, en función del número de años que ha jugado en las grandes ligas y el número de hits que realizó en el año anterior.}}{27}{figure.2.9}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Analogía del comité de expertos en XGBoost: cada árbol corrige los errores de sus predecesores y contribuye a una predicción final más precisa de la GHI.}}{30}{figure.2.10}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Ejemplo de un árbol de decisión simple. XGBoost combina cientos de estos árboles débiles para construir un modelo poderoso.}}{31}{figure.2.11}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Proceso iterativo: cada nuevo árbol corrige los errores del modelo acumulado.}}{32}{figure.2.12}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Esquema conceptual: múltiples árboles (\textit {expertos}) corrigen iterativamente sus errores para formar un modelo robusto.}}{33}{figure.2.13}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces Dinámica de entrenamiento de un modelo de aprendizaje automático. La curva azul muestra el error de entrenamiento, que disminuye progresivamente a medida que el modelo se ajusta a los datos. La curva naranja representa el error de validación, que disminuye inicialmente reflejando la mejora de la capacidad de generalización, pero comienza a aumentar después de la mejor época (línea roja discontinua), evidenciando el sobreajuste.}}{34}{figure.2.14}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Ubicación de la estaciones de medida}}{37}{figure.3.1}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Comparación del desempeño de los modelos CAMS y LSA-SAF en cinco sitios de estudio (Yu, Sa, Sca, Er y Lq) mediante las tres métricas estadísticas: Mean Bias Error (MBE), Mean Absolute Error (MAE) y Root Mean Square Error (RMSE) expresadas en términos relativos a escala 15-minutal.}}{40}{figure.3.2}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Figura \ref {fig:season-15}. Variación estacional del rRMSE (\%) para los productos CAMS y LSA-SAF con resolución de 15 minutos en todos los sitios de estudio. Se evidencia un aumento del error durante el verano en la mayoría de los sitios, mientras que en Yuto el rRMSE se mantiene estable, sugiriendo que la presencia de nubosidad estacional afecta de manera diferenciada la precisión de las estimaciones de radiación solar.}}{41}{figure.3.3}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Variación del error cuadrático medio relativo (RRMSD) en función del indice de claridad (kt) para los cinco sitios analizados (YU, SA, SCA, ERO y LQ). Resultados para CAMS (líneas continuas) y LSASAF (líneas punteadas).}}{42}{figure.3.4}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Variación del error cuadrático medio relativo (RRMSD) en función del ángulo cenital solar (SZA) para los cinco sitios analizados (YU, SA, SCA, ERO y LQ). Resultados para CAMS (líneas continuas) y LSASAF (líneas punteadas).}}{43}{figure.3.5}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces RMSE en resolución de 15 minutos para cada modelo y sitio, comparando modelos sin adaptación y adaptados.}}{47}{figure.3.6}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Comparación de modelos CAMS y LSASAF y las adpaciones con SLR y MLP en Yuto.}}{48}{figure.3.7}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Comparación de modelos CAMS y LSASAF y las adaptaciones con SLR Y MLP en Salta.}}{49}{figure.3.8}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Comparación de modelos CAMS y LSASAF y las adpataciones con SLR y MLP en San Carlos.}}{49}{figure.3.9}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Comparación de modelos CAMS y LSASAF y las adaptaciones con SLR y MLP en El Rosal.}}{50}{figure.3.10}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Comparación de modelos CAMS y LSASAF y las adaptaciones con SLR y MLP en La Quiaca.}}{50}{figure.3.11}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Comparación del RMSE(\%) para los modelos crudos y el mejor desempeño obtenido.}}{51}{figure.3.12}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Flujo de procesamiento para la adaptación de GHI en un sitio. A partir de un conjunto de medida, los datos pasan por un control de calidad y en paralelo se obtienen variables regresoras de reanálisis y geométricas. Con estas se entrenan modelos de regresión en dos enfoques: usando todas las variables disponibles o aplicando selección de características. El segundo enfoque genera un núcleo de variables que es refinado con Random Forest para identificar las más relevantes. Finalmente, se comparan las métricas de desempeño entre los modelos construidos con todas las variables y aquellos basados en las variables óptimas.}}{56}{figure.3.13}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Comparación del rendimiento entre el modelo original y los modelos ajustados con 15, 7 y 1 regresor en términos de RMSD. Las barras se muestran agrupadas por sitio y conjunto de datos, junto con flechas que indican la mejora o el deterioro con respecto al modelo original, así como deltas en puntos porcentuales (pp) y porcentaje relativo.}}{60}{figure.3.14}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Diferencias entre los tres enfoques de adaptación.}}{64}{figure.3.15}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces Grilla }}{66}{figure.3.16}%
\addvspace {10\p@ }
